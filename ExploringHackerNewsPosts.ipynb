{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project, we will explore different types of posts from Hacker News, a site where user-submitted stories are voted and commented upon. We are specifically interested in posts whose title begin with Ask HN and Show HN.\n",
    "\n",
    "Users submit Ask HN posts to ask Hacker News community a specific question and Show HN posts to show the Hacker News community a project or something interesting.\n",
    "\n",
    "Our goal is to analyze the posts to determine the following:\n",
    "\n",
    "- What kind of posts receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "Collecting data takes significant amount of time and energy.So we must always try to find relevant existing dataset.Luckily, there is a datset that is suitable for our purpose.This dataset is available on Kaggle.\n",
    "\n",
    "[A data set](https://www.kaggle.com/hacker-news/hacker-news-posts) containing approximately 300,000 posts from Hacker News.\n",
    "\n",
    "NOTE: This dataset has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all the submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "We can see that the dataset contains title of the posts, number of points and comments for each post and the date the posts were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open(\"hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "# Removing headers #\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating Ask HN and Show HN posts\n",
    "\n",
    "Since we are interested only in the post titles beginning with Ask HN and Show HN, it would be better to isolate them into different lists. Separating the data makes analyzing easier in the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n"
     ]
    }
   ],
   "source": [
    "print(len(ask_posts)) # Ask HN posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162\n"
     ]
    }
   ],
   "source": [
    "print(len(show_posts)) # Show HN posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17194\n"
     ]
    }
   ],
   "source": [
    "print(len(other_posts)) # other posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "Now we have separated the Ask HN and Show HN posts, we will calculate the average number of comments for each type of posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "# Total Number of comments for Ask HN posts #\n",
    "total_ask_comments = 0\n",
    "for post in ask_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "# Total Number of comments for Show HN posts #\n",
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above findings, we see that Ask Posts receive 14 comments on an average and Show Posts receive 10 comments on an average. Since Ask Posts receive more comments, we will focus our remaining analysis on these posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "\n",
    "Next, we will determine if Ask Posts created at a certain time are more likely to attract comments. First we will find the amount of Ask Posts created in each hour of the day, along with the number of comments received. Then we will calculate the average number of comments Ask Posts receive by hour created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    comments = int(post[4])\n",
    "    result_list.append([created_at,comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    hour = row[0]\n",
    "    comment = row[1]\n",
    "    time = dt.datetime.strptime(hour, \"%m/%d/%Y %H:%M\").strftime(\"%H\")\n",
    "    if time in counts_by_hour:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += comment\n",
    "    else:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = comment\n",
    "\n",
    "#counts_by_hour\n",
    "comments_by_hour\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN posts by Hour\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['11', 11.051724137931034], ['22', 6.746478873239437], ['16', 16.796296296296298], ['13', 14.741176470588234], ['04', 7.170212765957447], ['01', 11.383333333333333], ['19', 10.8], ['18', 13.20183486238532], ['15', 38.5948275862069], ['17', 11.46], ['05', 10.08695652173913], ['12', 9.41095890410959], ['20', 21.525], ['07', 7.852941176470588], ['06', 9.022727272727273], ['03', 7.796296296296297], ['14', 13.233644859813085], ['23', 7.985294117647059], ['08', 10.25], ['10', 13.440677966101696], ['09', 5.5777777777777775], ['21', 16.009174311926607], ['00', 8.127272727272727], ['02', 23.810344827586206]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for post in comments_by_hour:\n",
    "    avg_by_hour.append([post,comments_by_hour[post]/counts_by_hour[post]])\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Printing the Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.051724137931034, '11'], [6.746478873239437, '22'], [16.796296296296298, '16'], [14.741176470588234, '13'], [7.170212765957447, '04'], [11.383333333333333, '01'], [10.8, '19'], [13.20183486238532, '18'], [38.5948275862069, '15'], [11.46, '17'], [10.08695652173913, '05'], [9.41095890410959, '12'], [21.525, '20'], [7.852941176470588, '07'], [9.022727272727273, '06'], [7.796296296296297, '03'], [13.233644859813085, '14'], [7.985294117647059, '23'], [10.25, '08'], [13.440677966101696, '10'], [5.5777777777777775, '09'], [16.009174311926607, '21'], [8.127272727272727, '00'], [23.810344827586206, '02']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "print(swap_avg_by_hour)\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "sorted_swap\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments:\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Top 5 Hours for Ask Posts Comments #\n",
    "print(\"Top 5 Hours for Ask Posts Comments:\")\n",
    "for avg,hr in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(hr,\"%H\").strftime(\"%H:%M\")\n",
    "    print(\"{}: {:.2f} average comments per post\".format(hour,avg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour that recevies most number of comments per post on an average is 15:00. According to dataset documentation, the timezone used is Eastern Time in the US. So, we can say 15:00 is 3:00 PM est."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we analyzed the Ask HN and Show HN posts from Hacker Rank website to determine which type of post and time receive most comments on average. Based on our analysis, we concluded that of the posts that received comments, Ask Posts got more comments on average and the Ask Posts created at 15:00 received the most number of comments on an average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
